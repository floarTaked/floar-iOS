//
//  CardPreviewViewController.m
//  WeLinked4
//
//  Created by jonas on 5/16/14.
//  Copyright (c) 2014 jonas. All rights reserved.
//

#import "CardPreviewViewController.h"
#import "SaveCardViewController.h"
#import "LogicManager.h"
#import "VcardParser.h"
@interface CardPreviewViewController ()
@end
@implementation CardPreviewViewController
@synthesize stillImageOutput;
- (id)initWithNibName:(NSString *)nibNameOrNil bundle:(NSBundle *)nibBundleOrNil
{
    self = [super initWithNibName:nibNameOrNil bundle:nibBundleOrNil];
    if (self)
    {
        // Custom initialization
    }
    return self;
}

- (void)viewDidLoad
{
    [super viewDidLoad];
    recognizer = [[ISWebRecognizer alloc]init];
    recognizer.language = BCRLanguageChinese_Simplified;
    recognizer.userName = @"shu.wu@leku.com";
    recognizer.password = @"HA7KE4L5TMLAGRAN";
    
    
    [[UIApplication sharedApplication] setStatusBarHidden:YES];
#if !(TARGET_IPHONE_SIMULATOR)
    session = [[AVCaptureSession alloc] init];
	session.sessionPreset = AVCaptureSessionPresetHigh;
    
    
	AVCaptureDevice *device = [AVCaptureDevice defaultDeviceWithMediaType:AVMediaTypeVideo];
	NSError *error = nil;
	AVCaptureDeviceInput *input = [AVCaptureDeviceInput deviceInputWithDevice:device error:&error];
	if (!input)
    {
		NSLog(@"ERROR: trying to open camera: %@", error);
	}
	[session addInput:input];
    
	stillImageOutput = [[AVCaptureStillImageOutput alloc] init];
	NSDictionary *outputSettings = [[NSDictionary alloc] initWithObjectsAndKeys: AVVideoCodecJPEG, AVVideoCodecKey, nil];
	[stillImageOutput setOutputSettings:outputSettings];
	[session addOutput:stillImageOutput];
    AVCaptureVideoDataOutput *captureOutput = [[AVCaptureVideoDataOutput alloc] init];
	captureOutput.alwaysDiscardsLateVideoFrames = YES;
	dispatch_queue_t queue;
	queue = dispatch_queue_create("cameraQueue", NULL);
	[captureOutput setSampleBufferDelegate:self queue:queue];
    
	[captureOutput setVideoSettings:[NSDictionary dictionaryWithObjectsAndKeys:[NSNumber numberWithUnsignedInt:kCVPixelFormatType_32BGRA],
                                     (NSString*)kCVPixelBufferPixelFormatTypeKey,
                                     nil]];
    [session addOutput:captureOutput];
#endif
}
-(void)viewWillAppear:(BOOL)animated
{
    [super viewWillAppear:animated];
    captureImageView.image = nil;
    previewImageView.hidden = NO;
    if(session != nil && ![session isRunning])
    {
        [session startRunning];
    }
}
-(void)viewWillDisappear:(BOOL)animated
{
    [super viewWillDisappear:animated];
    [[UIApplication sharedApplication] setStatusBarHidden:NO];
    if([session isRunning])
    {
        [session stopRunning];
    }
}
-(void)setEventCallBack:(EventCallBack)call
{
    callback = call;
}
-(void)processImage:(UIImage*)image
{
    maskView = [[UIView alloc]initWithFrame:CGRectMake(0, 0, captureImageView.frame.size.width, captureImageView.frame.size.height)];
    maskView.backgroundColor = [UIColor colorWithRed:0.5 green:0.5 blue:0.5 alpha:0.5];
    [captureImageView addSubview:maskView];
    
    [recognizer cropAndRecognizeImage:image croppedHandler:^(UIImage *cropAndEnhancedImage){
        if(cropAndEnhancedImage != nil)
        {
            captureImageView.image = cropAndEnhancedImage;
        }
    }completionHandler:^(NSString *vCardRepresentation, NSError *error){
        [self processAnimation:vCardRepresentation image:captureImageView.image];
    }];
}
-(void)processAnimation:(NSString*)value image:(UIImage*)image
{
    [UIView animateWithDuration:3 animations:^{
        maskView.frame = CGRectMake(0,captureImageView.frame.size.height,captureImageView.frame.size.width, 0);
    } completion:^(BOOL finished) {
        [maskView removeFromSuperview];
        VcardParser* parser = [[VcardParser alloc]init];
        [parser setVCardRepresentation:value];
        [parser startSynchronously:YES block:^(int event, id object)
        {
            if(event == ParserDidStartVCard)
            {
                [parseResult removeAllObjects];
                parseResult = [[NSMutableDictionary alloc]init];
            }
            else if(event == Parser)
            {
                NSDictionary* dic = (NSDictionary*)object;
                [parseResult setObject:[dic objectForKey:@"parsedValue"] forKey:[dic objectForKey:@"key"]];
            }
            else if (event == ParserDidEndVCard)
            {
                SaveCardViewController* save = [[SaveCardViewController alloc]initWithNibName:@"SaveCardViewController" bundle:nil];
                
                float ang = 0;
                NSNumber* angle = [parseResult objectForKey:@"X-IS-ANGLE"];
                if(angle != nil)
                {
                    ang = [angle floatValue];
                }
                save.card = [image imageRotatedByDegrees:-ang];
                save.value = parseResult;
                [save setEventCallBack:callback];
                UINavigationController* nav = [[UINavigationController alloc]initWithRootViewController:save];
                [Common setNavigationBarWMStyle];
                [self presentViewController:nav animated:YES completion:nil];
            }
        }];
    }];
}
- (void)didReceiveMemoryWarning
{
    [super didReceiveMemoryWarning];
    // Dispose of any resources that can be recreated.
}
- (void)viewDidAppear:(BOOL)animated
{
    [super viewDidAppear:animated];
}
#pragma mark - Video Frame Delegate
- (void)captureOutput:(AVCaptureOutput *)captureOutput
didOutputSampleBuffer:(CMSampleBufferRef)sampleBuffer
	   fromConnection:(AVCaptureConnection *)connection
{
    UIImage* image = [self imageFromSampleBuffer:sampleBuffer];
    runOnMainQueueWithoutDeadlocking(^{
        previewImageView.image = image;
    });
}
- (UIImage *)imageFromSampleBuffer:(CMSampleBufferRef) sampleBuffer
{
    // Get a CMSampleBuffer's Core Video image buffer for the media data
    CVImageBufferRef imageBuffer = CMSampleBufferGetImageBuffer(sampleBuffer);
    // Lock the base address of the pixel buffer
    CVPixelBufferLockBaseAddress(imageBuffer, 0);
    
    // Get the number of bytes per row for the pixel buffer
    void *baseAddress = CVPixelBufferGetBaseAddress(imageBuffer);
    
    // Get the number of bytes per row for the pixel buffer
    size_t bytesPerRow = CVPixelBufferGetBytesPerRow(imageBuffer);
    // Get the pixel buffer width and height
    size_t width = CVPixelBufferGetWidth(imageBuffer);
    size_t height = CVPixelBufferGetHeight(imageBuffer);
    
    // Create a device-dependent RGB color space
    CGColorSpaceRef colorSpace = CGColorSpaceCreateDeviceRGB();
    
    // Create a bitmap graphics context with the sample buffer data
    CGContextRef context = CGBitmapContextCreate(baseAddress, width, height, 8,
                                                 bytesPerRow, colorSpace, kCGBitmapByteOrder32Little | kCGImageAlphaPremultipliedFirst);
    // Create a Quartz image from the pixel data in the bitmap graphics context
    CGImageRef quartzImage = CGBitmapContextCreateImage(context);
    // Unlock the pixel buffer
    CVPixelBufferUnlockBaseAddress(imageBuffer,0);
    
    // Free up the context and color space
    CGContextRelease(context);
    CGColorSpaceRelease(colorSpace);
    
    // Create an image object from the Quartz image
    //UIImage *image = [UIImage imageWithCGImage:quartzImage];
    UIImage *image = [UIImage imageWithCGImage:quartzImage scale:1.0f orientation:UIImageOrientationRight];
    
    // Release the Quartz image
    CGImageRelease(quartzImage);
    
    return (image);
}
-(IBAction)takePhoto:(id)sender
{
    AVCaptureConnection *videoConnection = nil;
	for (AVCaptureConnection *connection in stillImageOutput.connections)
	{
		for (AVCaptureInputPort *port in [connection inputPorts])
		{
			if ([[port mediaType] isEqual:AVMediaTypeVideo] )
			{
				videoConnection = connection;
				break;
			}
		}
		if (videoConnection)
        {
            break;
        }
	}
	[stillImageOutput captureStillImageAsynchronouslyFromConnection:videoConnection
                                                  completionHandler: ^(CMSampleBufferRef imageSampleBuffer, NSError *error)
     {
         NSData *imageData = [AVCaptureStillImageOutput jpegStillImageNSDataRepresentation:imageSampleBuffer];
         UIImage *image = [[UIImage alloc] initWithData:imageData];
         previewImageView.hidden = YES;
         if([session isRunning])
         {
             [session stopRunning];
         }
         [self processImage:image];
	 }];
}
-(IBAction)cancelAction:(id)sender
{
    [self dismissViewControllerAnimated:YES completion:nil];
}
-(IBAction)contactAction:(id)sender
{
    
}
-(IBAction)cardAction:(id)sender
{
    
}
-(IBAction)QRAction:(id)sender
{
    
}
@end
